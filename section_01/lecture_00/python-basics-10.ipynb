{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Basics 10: The Python Data Analysis Library\n",
    "\n",
    "The objectives of this notebook are:\n",
    "\n",
    "+ to introduce students to the pandas library, including loading data files in python, cleaning data, removing null values, indexing of pandas dataframes, selecting data columns, and some basic plotting\n",
    "\n",
    "Special thanks to [Vanessa Kwarteng](https://www.predictivesciencelab.org/authors/vanessa/) for putting this Jupyter notebook together.\n",
    "\n",
    "## Pandas Introduction\n",
    "\n",
    "**What is pandas?** Pandas is a python package that provides fast, flexible and data structures that lets you work real life data quickly. More information about the pandas package can be found [here](https://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html)\n",
    "\n",
    "In order to use pandas in python we need to import the library into the notebook, as shown in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries needed\n",
    "\n",
    "import numpy as np   # matrix and linear algebra\n",
    "import pandas as pd  # python data analysis library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Loading files\n",
    "\n",
    "If we want to look at data we have collected for a project or experiment, we need to upload that data into jupyter notebook. To do this we can import the file using a `pandas` command. Pandas is able to read various types of files, in this activity we will be using pandas to read a [csv (comma separated values) file](https://en.wikipedia.org/wiki/Comma-separated_values).\n",
    "\n",
    "To import the csv file in Python we use the following command `pandas.read_csv`. In Python there are some common shorthand we can use, `pandas` is typically shorten to `pd`. So we will use `pd.read_csv` to import the data file that we will work with.\n",
    "<br><br>\n",
    "\n",
    "## Dataset \n",
    "Scenario: A researcher wants to gain some insight about energy usage in apartment homes in a community and provide a grade for each apartments energy usage. The dataset `temp_price.csv` that you are given contains HVAC energy usage data collected from 50 apartment homes in one day\n",
    "+ The apartment ID number (household)\n",
    "+ The outdoor temperature for the day (t_out)\n",
    "+ The indoor temperature of the apartment for the day (t_unit)\n",
    "+ The amount of kwh consumed by the HVAC system for the day (hvac)\n",
    "+ The price per kwh used (price)\n",
    "+ The price per week for using the hvac (Price per week)\n",
    "+ The price per day for using the hvac (Price per day)\n",
    "\n",
    "Let's import the data to explore. This dataset is small, so that you will be able to see the changes you are making in order to become comfortable with cleaning data. In the future you will work with larger sized data sets.\n",
    "\n",
    "The dataset can be accessed in this link:\n",
    "\n",
    "https://raw.githubusercontent.com/PredictiveScienceLab/data-analytics-se/master/activities/temp_price.csv\n",
    "\n",
    "If you run Jupyter your PC, then all you have to do is to download this file and put it in the same directory as the notebook.\n",
    "If you work on Google Colab things are a bit more complicated.\n",
    "We will show you how to do it later in the homework problems.\n",
    "For now, let us just sprinkle some magick code that downloads the file and puts it in a spot that Google Colab can see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you run this on Google Colab\n",
    "import requests\n",
    "import os\n",
    "def download(url, local_filename=None):\n",
    "    \"\"\"\n",
    "    Downloads the file in the ``url`` and saves it in the current working directory.\n",
    "    \"\"\"\n",
    "    data = requests.get(url)\n",
    "    if local_filename is None:\n",
    "        local_filename = os.path.basename(url)\n",
    "    with open(local_filename, 'wb') as fd:\n",
    "        fd.write(data.content)\n",
    "   \n",
    "# The url of the file we want to download\n",
    "url = 'https://raw.githubusercontent.com/PredictiveScienceLab/data-analytics-se/master/activities/temp_price.csv'\n",
    "download(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should have access to the ``temp_price.csv`` file from within this notebook and the following code should work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads a csv file into the pandas framework\n",
    "temp_price = pd.read_csv('temp_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays how pandas looks at the file\n",
    "temp_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations from the dataset so far\n",
    "\n",
    "The very first column is the index of each entry. Notice how python counts the rows, it starts with 0 and not 1. This is different than other programming softwares that start counting from 1. Then you have columns with various names. The first column is the \"household\" id, then the \"date,\" etc.\n",
    "**Questions:** What are some other things you notice about the data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue to explore the data. The following function gives you a summary of the satistics of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This provides the statistics of each column \n",
    "temp_price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing specific ranges\n",
    "\n",
    "In this next section we look at different ways to quickly get some insight about the data and also how to look at specific columns, rows, etc. \n",
    "\n",
    "If we want to look at specific locations in the data we can do the following: \n",
    "\n",
    "+ `head()` - the default displays the first 5 rows\n",
    "+ `tail()` - the default displays the last 5 rows\n",
    "\n",
    "The way you can think about the syntax when using pandas is `Dataframe_name.action_to_be_done(params_if_needed)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will print the first 10 rows\n",
    "# Let's print out the first 10 rows, what would you do?\n",
    "temp_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prints the last 5 rows\n",
    "temp_price.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you wanted to print the first 7 rows (instead of the first 5) you would do this:\n",
    "temp_price.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the last 12 rows, what would you do?\n",
    "temp_price.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "\n",
    "In the `temp_price` file you notice that some cells have -100 under the score column, -100.0 under the t_unit or NaN value for hvac. There are various reasons for this, but the details around it are not helpful for this point. We will focus on the `NaN`.\n",
    "\n",
    "When you see `NaN` this means that the value here is **Not a Number** and this is the pythonic notation to display that. For this example, when we see NaN that means that this unit is missing over 70% of its data for the week. This most likely means that the sensor for the unit needs to be replaced. \n",
    "\n",
    "Having these -100, -100.0 and NaN can mess with the interpretation of our anaylsis, so we want to clean the data to remove the corresponding observations. \n",
    "\n",
    "To do this we will use `dropna()` to remove the rows that have NaN. To get a better understanding of how `dropna()` works we can look at the documentation for it: [pandas dropna docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html)\n",
    "+ Look at the documentation to see what the axis needs to be in order to remove rows vs. columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN rows from the table\n",
    "temp_no_null_rows = temp_price.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print data with no NaN rows\n",
    "temp_no_null_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you notice?**\n",
    "+ Do you see any NaN or -100 values in the dataset?\n",
    "+ Do we still have the same number of indicies? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `DataFrame.shape` to compare the previous table with the removal of the `NaN` to double check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of data after cleaning\n",
    "temp_no_null_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of data before cleaning\n",
    "temp_price.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `shape()` tells the number of rows and columns of the dataset. \n",
    "\n",
    "### Note\n",
    "\n",
    "When dealing with columns, you typically want to keep everything lowercase and remove spaces. So to rename an existing column in the dataframe we can do the following: `df.rename(columns={'current_name' : 'new_name'}, inplace=True)`\n",
    "\n",
    "Let's rename `Price per week` to `week_price` and `Price per day` to `daily_price`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the title of columns\n",
    "clean_data = temp_no_null_rows.rename(columns={'Price per week': 'week_price',\n",
    "                                               'Price per day': 'daily_price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the the column names have changed\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you may be wandering what exactly is:\n",
    "```\n",
    "columns={'Price per week': 'week_price',\n",
    "         'Price per day': 'daily_price'}\n",
    "```\n",
    "This defines a *dictionary*.\n",
    "It is a special Python class called ``dict``.\n",
    "See [Sec. 5.5 here](https://docs.python.org/3/tutorial/datastructures.html).\n",
    "But let's also run it separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns={'Price per week': 'week_price',\n",
    "         'Price per day': 'daily_price'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns['Price per week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns['Price per day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, ``rename`` looks at the dictionary for keys that are column names and then replacs the corresponding column name with whatever the dictionary indicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have clean data, we can explore the data set with the following actions: \n",
    "\n",
    "+ `df['column_name']` - to select a single column from the dataframe\n",
    "+ `df[['column_name1', 'column_name7']]` - to select a lists of columns from dataframe\n",
    "+ `df.loc[rowindex1]` - to select a single row from the dataframe\n",
    "+ `df.loc[[rowindex1, rowindex2]]` - to select a list of rows from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single column\n",
    "clean_data['household']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select multiple columns\n",
    "clean_data[['household', 'daily_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a row\n",
    "clean_data.loc[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select certain rows\n",
    "clean_data.loc[[25,39, 45]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a slice of rows\n",
    "clean_data.loc[25:36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can do even more complicated things.\n",
    "For example, let's say that we wan to select all rows with a score greater than 80.\n",
    "How would we do this?\n",
    "Here it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First you create an array of booleans indicating whether or not a\n",
    "# row satisfies a constraint\n",
    "idx = clean_data['score'] > 80\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now you can just use these indices to get a slice of the data frame:\n",
    "clean_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And here is how you would pick all rows with score between 80 and 90:\n",
    "idx = (clean_data['score'] > 80) & (clean_data['score'] < 90)\n",
    "clean_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And here is how you would pick all rows with score less than 20 or greater than 90:\n",
    "idx = (clean_data['score'] < 20) | (clean_data['score'] > 90)\n",
    "clean_data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there many more things that you can easily do with pandas.\n",
    "There are so many things to do with pandas that you can spend weeks on this library alone.\n",
    "Our suggestion is to learn pandas as needed when you experiment with data files.\n",
    "Typically, if you think about what you need to do, you can find how to do it in pandas with a good Google search.\n",
    "\n",
    "## Questions\n",
    "\n",
    "+ Write pandas code that extracts the `week_price` column from `clean_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Write pandas code that extracts all rows with `week_price` less than 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Write pandas code that gives you how many households have a `score` greater than 50 and a `week_price` less than 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
