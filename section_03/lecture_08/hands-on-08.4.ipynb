{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Activity 8.4: Sampling Estimates of Variance\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- To use the law of large numbers to estimate variances \n",
    "\n",
    "## Estimating the variance\n",
    "We now want to estimate the variance:\n",
    "$$\n",
    "V = \\mathbb{V}[g(X)],\n",
    "$$\n",
    "using some sort of sampling average.\n",
    "Notice that:\n",
    "$$\n",
    "V = \\mathbb{V}[g(X)] = \\mathbb{E}[g^2(X)] - \\left(\\mathbb{E}[g(X)]\\right)^2.\n",
    "$$\n",
    "We already know how to estimate the last term, see definition of $\\bar{I}_N$ in the previous subsection.\n",
    "To approximate the other term, consider the random variables $g^2(X_1),g^2(X_2),\\dots$.\n",
    "These are independent and identically distributed so by the law of large numbers we get that:\n",
    "$$\n",
    "\\frac{g^2(X_1)+\\dots+g^2(X_N)}{N}\\rightarrow \\mathbb{E}[g^2(X)],\\;\\text{a.s.}\n",
    "$$\n",
    "Putting everything together, we get that:\n",
    "$$\n",
    "\\bar{V}_N = \\frac{1}{N}\\sum_{i=1}^Ng^2(X_i) - \\bar{I}_N^2\\rightarrow V\\;\\text{a.s.}\n",
    "$$\n",
    "\n",
    "### Example: 1D variance\n",
    "\n",
    "Let's try it out with a test function in 1D (Example 3.4 of Robert & Casella (2004)).\n",
    "Assume that $X\\sim\\mathcal{U}([0,1])$ and pick:\n",
    "$$\n",
    "g(x) = \\left(\\cos(50x) + \\sin(20x)\\right)^2.\n",
    "$$\n",
    "The correct value for the variance is:\n",
    "$$\n",
    "\\mathbb{V}[g(X)] \\approx 1.093.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function\n",
    "g = lambda x: (np.cos(50 * x) + np.sin(20 * x)) ** 2\n",
    "\n",
    "# Number of samples to take\n",
    "N = 100\n",
    "# Generate samples from X\n",
    "x_samples = np.random.rand(N)\n",
    "# Get the corresponding Y's\n",
    "y_samples = g(x_samples)\n",
    "# Evaluate the sample average E[g(X)] for all sample sizes\n",
    "I_running = np.cumsum(y_samples) / np.arange(1, N + 1)\n",
    "# Evaluate the sample average for E[g^2(X)] for all sample sizes\n",
    "I2_running = np.cumsum(y_samples ** 2) / np.arange(1, N + 1)\n",
    "# Build the sample average for V[g(X)]\n",
    "V_running = I2_running - I_running ** 2\n",
    "\n",
    "# Plot a running estimate of the variance\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.plot(np.arange(1, N+1), V_running)\n",
    "ax.plot(np.arange(1, N+1), [1.093] * N, color='r')\n",
    "ax.set_xlabel('$N$')\n",
    "ax.set_ylabel(r'$\\bar{V}_N$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Increase ``N`` until you get an answer that is close enough to the correct answer (the red line).\n",
    "+ Reduce ``N`` back to a small number, say 1,000. Run the code 2-3 times to observe that every time you get a slightly different answer..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
